---
published: true
title: Related Studies on Watermarks in Large Language Model
tags: LLM AI-security
---
I'm writing this blog to conclude some of the representative papers about watermarks in large language models. 

***Table of Contents***
* TOC
{:toc}

# Introduction
---

*Watermarks were first introduced in Fabriano, Italy, in 1282. At the time, watermarks were created by changing the thickness of paper during a stage in the manufacturing process when it was still wet.*

*(Wikipedia)*

---
It would be great if large language models could add watermarks to the texts they generate. With watermarks on AI-generated text, the user could verify whether a segment of text was generated by a specific LLM, while the owner of the LLM could claim or deny responsibility for the text generated by the LLM.

Unlike watermarks on images, it is much more difficult to add watermarks to texts without distorting the original meaning. One cannot simply insert a segment of text as a watermark, as it can be easily removed. Therefore, watermarks for LLMs should be embedded in the text in a way that preserves the semantics, while a specific process can be followed to extract the watermark and verify if the text was generated by the LLM.

# Methodologies
Adding watermarks in LLM-generated texts can be methodologically categorized into: Rule-based watermarking, Inference-time watermarking, Neural-based watermarking [1]. 

# Use Cases

# Reference
[1]: https://arxiv.org/pdf/2303.07205